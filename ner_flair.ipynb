{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff096c7c-98a9-4a35-a370-0937d79f9027",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff096c7c-98a9-4a35-a370-0937d79f9027",
    "outputId": "d49eef11-3562-443a-c8cc-e56c398c32e2"
   },
   "outputs": [],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "from flair.tokenization import SegtokSentenceSplitter\n",
    "import numpy as np\n",
    "import csv\n",
    "import os.path\n",
    "import json\n",
    "\n",
    "# relevant entity types:\n",
    "# ----------------------\n",
    "# FAC\tbuilding name\n",
    "# GPE\tgeo-political entity\n",
    "# LOC\tlocation name\n",
    "# NORP\taffiliation\n",
    "# ORG\torganization name\n",
    "# PERSON\tperson name\n",
    "\n",
    "relevant_ent_types = ['FAC', 'GPE', 'LOC', 'NORP', 'PERSON', 'ORG', 'MISC']\n",
    "\n",
    "flair_18class = SequenceTagger.load('flair/ner-english-ontonotes-large')\n",
    "# flair_12class = SequenceTagger.load('ner-ontonotes-fast')\n",
    "# flair_4class = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc4deb-295f-4102-9e07-be484b90a62f",
   "metadata": {
    "id": "0cdc4deb-295f-4102-9e07-be484b90a62f"
   },
   "outputs": [],
   "source": [
    "# get data (full texts of documents including acknowledgements, foreword, executive summary and body)\n",
    "f = open('data.json')\n",
    "data = json.load(f)\n",
    "\n",
    "# get data (the structured data which Malte processed into lines with metadata)\n",
    "sf = open('studies_on_water_scraped.json')\n",
    "malte_data = json.load(sf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TPha0WaPLcfU",
   "metadata": {
    "id": "TPha0WaPLcfU"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_multiple_whitespaces\n",
    "\n",
    "# define preprocessing steps\n",
    "def preprocess(text):\n",
    "    # remove URLs\n",
    "    text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "    text = re.sub('http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub('^(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?$', '', text)\n",
    "    \n",
    "    # remove HTML / XML-like tags in text and multiple whitespaces\n",
    "    CUSTOM_FILTERS = [strip_tags, strip_multiple_whitespaces]\n",
    "    text_tokens = preprocess_string(text, CUSTOM_FILTERS)\n",
    "    \n",
    "    # remove niche irrelevant characters\n",
    "    irrelevant_tokens = ['et', 'al.', 'x', 'pdf', 'yes', 'abbrev','fe',\n",
    "                            'page', 'pp', 'p', 'er', 'doi', 'can', 'b', 'c', 'd', 'e',\n",
    "                            'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'o', 'q', 'r', 's',\n",
    "                            't', 'u', 'v', 'w', 'y', 'z','www', 'com', 'org', 'de', 'dx', 'th', 'ii', 'le']\n",
    "\n",
    "    tokens_without_sw = [word.strip() for word in text_tokens if not word.strip() in irrelevant_tokens]\n",
    "    text = ' '.join(tokens_without_sw)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7TPDXqwSLiOp",
   "metadata": {
    "id": "7TPDXqwSLiOp"
   },
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "for key in data:\n",
    "    data[key] = preprocess(data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "-QmKcjk4MZ2h",
   "metadata": {
    "id": "-QmKcjk4MZ2h"
   },
   "outputs": [],
   "source": [
    "# define function to lookup correct ID for document in studies_on_water_scraped.json\n",
    "# before this, I was using the INDEX of the document in the JSON array of this file as its ID.\n",
    "def lookup_correct_docid(old_key):\n",
    "    global malte_data\n",
    "    return malte_data[int(old_key)]['meta']['id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7647a06-b78c-45a5-91a0-5afceb3b327f",
   "metadata": {
    "id": "b7647a06-b78c-45a5-91a0-5afceb3b327f"
   },
   "outputs": [],
   "source": [
    "# function to split sentence list into chunks for batch processing by GPU\n",
    "def split(list_a, chunk_size):\n",
    "    for i in range(0, len(list_a), chunk_size):\n",
    "        yield list_a[i:i + chunk_size]\n",
    "\n",
    "# do NER tagging on a given document\n",
    "def flair_ner(document, model, docid):\n",
    "    results = []\n",
    "    splitter = SegtokSentenceSplitter()\n",
    "    sentences = splitter.split(document)\n",
    "    batches = split(sentences, 20)\n",
    "\n",
    "    for batch in batches:\n",
    "        model.predict(batch)\n",
    "        for sentence in batch:        \n",
    "            for entity in sentence.get_spans('ner'):\n",
    "                if (entity.get_label(\"ner\").value in relevant_ent_types):\n",
    "                    if (len(entity.text) > 1): # one character entities disregarded\n",
    "                        results.append((entity.text.replace('\"', ''), entity.get_label(\"ner\").value, sentence.to_plain_string(), str(entity.start_position) + \":\" + str(entity.end_position), docid))\n",
    "                              \n",
    "    return results\n",
    "\n",
    "# write tagging results to CSV file\n",
    "def write_results_to_file(results, file):\n",
    "    if os.path.exists(file):\n",
    "        # append\n",
    "        with open(file, 'a+', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for item in results:\n",
    "                writer.writerow([str(item[0]), str(item[1]), str(item[2]), str(item[3]), str(item[4]), 'flair - FLERT and XML embeddings'])\n",
    "    else:\n",
    "        # create file from scratch\n",
    "        with open(file, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['entity', 'entity_type', 'sentence', 'span', 'docid', 'model'])\n",
    "            for item in results:\n",
    "                writer.writerow([str(item[0]), str(item[1]), str(item[2]), str(item[3]), str(item[4]), 'flair - FLERT and XML embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dfd99a-1cb8-4adb-80b3-847fd5385b4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7dfd99a-1cb8-4adb-80b3-847fd5385b4e",
    "outputId": "e324561d-372b-45c0-a5d3-9fffedce8ade"
   },
   "outputs": [],
   "source": [
    "# run the NER tagging on each document in the corpus\n",
    "import datetime;\n",
    "ct = datetime.datetime.now()\n",
    "print()\n",
    "print(\"Started entire run at:-\", ct)\n",
    "print(\"---\")\n",
    "print()\n",
    "\n",
    "for key in data:\n",
    "    ct = datetime.datetime.now()\n",
    "    print(\"Started processing Doc (\" + str(key) + \"-\" + str(lookup_correct_docid(key)) + \" / \" + \"55) at:-\", ct)\n",
    "    ner_results = flair_ner(data[key], flair_18class, lookup_correct_docid(key))\n",
    "    write_results_to_file(ner_results, 'master-ner-results.csv')\n",
    "    ct = datetime.datetime.now()\n",
    "    print(\"Finished processing Doc (\" + str(key) + \"-\" + str(lookup_correct_docid(key)) + \" / \" + \"55) at:-\", ct)\n",
    "\n",
    "print()\n",
    "ct = datetime.datetime.now()\n",
    "print(\"---\")\n",
    "print(\"Finished entire run at:-\", ct)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ner-flair.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
