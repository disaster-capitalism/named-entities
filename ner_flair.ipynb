{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff096c7c-98a9-4a35-a370-0937d79f9027",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff096c7c-98a9-4a35-a370-0937d79f9027",
    "outputId": "da0661ba-65d4-4e20-8435-7508842723a2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "/Users/kodymoodley/Documents/nlesc-projects/disaster-capitalism/flair/named-entities/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/kodymoodley/Documents/nlesc-projects/disaster-capitalism/flair/named-entities/venv/lib/python3.9/site-packages/huggingface_hub/file_download.py:560: FutureWarning: `cached_download` is the legacy way to download files from the HF hub, please consider upgrading to `hf_hub_download`\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-28 10:19:16,940 loading file /Users/kodymoodley/.flair/models/ner-english-ontonotes-large/2da6c2cdd76e59113033adf670340bfd820f0301ae2e39204d67ba2dc276cc28.ec1bdb304b6c66111532c3b1fc6e522460ae73f1901848a4d0362cdf9760edb1\n",
      "2022-06-28 10:19:44,470 SequenceTagger predicts: Dictionary with 76 tags: <unk>, O, B-CARDINAL, E-CARDINAL, S-PERSON, S-CARDINAL, S-PRODUCT, B-PRODUCT, I-PRODUCT, E-PRODUCT, B-WORK_OF_ART, I-WORK_OF_ART, E-WORK_OF_ART, B-PERSON, E-PERSON, S-GPE, B-DATE, I-DATE, E-DATE, S-ORDINAL, S-LANGUAGE, I-PERSON, S-EVENT, S-DATE, B-QUANTITY, E-QUANTITY, S-TIME, B-TIME, I-TIME, E-TIME, B-GPE, E-GPE, S-ORG, I-GPE, S-NORP, B-FAC, I-FAC, E-FAC, B-NORP, E-NORP, S-PERCENT, B-ORG, E-ORG, B-LANGUAGE, E-LANGUAGE, I-CARDINAL, I-ORG, S-WORK_OF_ART, I-QUANTITY, B-MONEY\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "from flair.tokenization import SegtokSentenceSplitter\n",
    "import numpy as np\n",
    "import csv\n",
    "import os.path\n",
    "import json\n",
    "\n",
    "# Relevant entity types:\n",
    "# ----------------------\n",
    "# FAC\tbuilding name\n",
    "# GPE\tgeo-political entity\n",
    "# LOC\tlocation name\n",
    "# NORP\taffiliation\n",
    "# ORG\torganization name\n",
    "# PERSON\tperson name\n",
    "\n",
    "relevant_ent_types = ['FAC', 'GPE', 'LOC', 'NORP', 'PERSON', 'ORG', 'MISC']\n",
    "\n",
    "flair_18class = SequenceTagger.load('flair/ner-english-ontonotes-large')\n",
    "# flair_12class = SequenceTagger.load('ner-ontonotes-fast')\n",
    "# flair_4class = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cdc4deb-295f-4102-9e07-be484b90a62f",
   "metadata": {
    "id": "0cdc4deb-295f-4102-9e07-be484b90a62f"
   },
   "outputs": [],
   "source": [
    "# Get data (full texts of documents including acknowledgements, foreword, executive summary and body)\n",
    "f = open('data.json')\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7647a06-b78c-45a5-91a0-5afceb3b327f",
   "metadata": {
    "id": "b7647a06-b78c-45a5-91a0-5afceb3b327f"
   },
   "outputs": [],
   "source": [
    "# Do NER tagging on a given document\n",
    "def flair_ner(document, model, docid):\n",
    "    results = []\n",
    "    splitter = SegtokSentenceSplitter()\n",
    "    sentences = splitter.split(document)\n",
    "    model.predict(sentences)\n",
    "    for sentence in sentences:        \n",
    "        for entity in sentence.get_spans('ner'):\n",
    "            if (entity.get_label(\"ner\").value in relevant_ent_types):\n",
    "                results.append((entity.text, entity.get_label(\"ner\").value, docid))\n",
    "                              \n",
    "    return list(set(results))\n",
    "\n",
    "# Write tagging results to CSV file\n",
    "def write_results_to_file(results, file):\n",
    "    if os.path.exists(file):\n",
    "        # append\n",
    "        with open(file, 'a+', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for item in results:\n",
    "                writer.writerow([str(item[0]), str(item[1]), str(item[2]), 'flair - FLERT and XML embeddings'])\n",
    "    else:\n",
    "        # create file from scratch\n",
    "        with open(file, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['entity', 'entity_type', 'docid', 'model'])\n",
    "            for item in results:\n",
    "                writer.writerow([str(item[0]), str(item[1]), str(item[2]), 'flair - FLERT and XML embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dfd99a-1cb8-4adb-80b3-847fd5385b4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7dfd99a-1cb8-4adb-80b3-847fd5385b4e",
    "outputId": "4a573403-ebbd-4f3e-936d-76f4229b3f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Started entire run at:- 2022-06-28 10:21:20.585983\n",
      "---\n",
      "\n",
      "Started processing Doc (1 / 55) at:- 2022-06-28 10:21:20.587040\n"
     ]
    }
   ],
   "source": [
    "# Run the NER tagging on each document in the corpus\n",
    "import datetime;\n",
    "ct = datetime.datetime.now()\n",
    "print()\n",
    "print(\"Started entire run at:-\", ct)\n",
    "print(\"---\")\n",
    "print()\n",
    "\n",
    "index = 1\n",
    "for key in data:\n",
    "    ct = datetime.datetime.now()\n",
    "    print(\"Started processing Doc (\" + str(index) + \" / \" + \"55) at:-\", ct)\n",
    "    ner_results = flair_ner(data[key], flair_18class, key)\n",
    "    write_results_to_file(ner_results, 'master-ner-results.csv')\n",
    "    ct = datetime.datetime.now()\n",
    "    print(\"Finished processing Doc (\" + str(index) + \" / \" + \"55) at:-\", ct)\n",
    "    index += 1\n",
    "\n",
    "print()\n",
    "ct = datetime.datetime.now()\n",
    "print(\"---\")\n",
    "print(\"Finished entire run at:-\", ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8a3a1-f53e-4659-9fe9-0a03a379f588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ner-flair.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
