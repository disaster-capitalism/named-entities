{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff096c7c-98a9-4a35-a370-0937d79f9027",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff096c7c-98a9-4a35-a370-0937d79f9027",
    "outputId": "da0661ba-65d4-4e20-8435-7508842723a2"
   },
   "outputs": [],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.data import Sentence\n",
    "from flair.tokenization import SegtokSentenceSplitter\n",
    "import numpy as np\n",
    "import csv\n",
    "import os.path\n",
    "import json\n",
    "\n",
    "# Relevant entity types:\n",
    "# ----------------------\n",
    "# FAC\tbuilding name\n",
    "# GPE\tgeo-political entity\n",
    "# LOC\tlocation name\n",
    "# NORP\taffiliation\n",
    "# ORG\torganization name\n",
    "# PERSON\tperson name\n",
    "\n",
    "relevant_ent_types = ['FAC', 'GPE', 'LOC', 'NORP', 'PERSON', 'ORG', 'MISC']\n",
    "\n",
    "flair_18class = SequenceTagger.load('flair/ner-english-ontonotes-large')\n",
    "# flair_12class = SequenceTagger.load('ner-ontonotes-fast')\n",
    "# flair_4class = SequenceTagger.load('ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdc4deb-295f-4102-9e07-be484b90a62f",
   "metadata": {
    "id": "0cdc4deb-295f-4102-9e07-be484b90a62f"
   },
   "outputs": [],
   "source": [
    "# Get data (full texts of documents including acknowledgements, foreword, executive summary and body)\n",
    "f = open('data.json', encoding='utf-8')\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c895d1a1-770e-4325-9fe6-a995d60b4b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "import re\n",
    "import gensim\n",
    "from gensim.parsing.preprocessing import preprocess_string, strip_tags, strip_multiple_whitespaces\n",
    "\n",
    "def preprocess(text):\n",
    "    # remove URLs\n",
    "    text = re.sub('http://\\S+|https://\\S+', '', text)\n",
    "    text = re.sub('http[s]?://\\S+', '', text)\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub('^(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/.*)?$', '', text)\n",
    "    \n",
    "    # remove HTML / XML-like tags in text and multiple whitespaces\n",
    "    CUSTOM_FILTERS = [strip_tags, strip_multiple_whitespaces]\n",
    "    text_tokens = preprocess_string(text, CUSTOM_FILTERS)\n",
    "    text = ' '.join(text_tokens)\n",
    "    \n",
    "    # remove niche irrelevant characters\n",
    "    irrelevant_tokens = ['et', 'al.', 'x', 'pdf', 'yes', 'abbrev', \n",
    "                            'page', 'pp', 'p', 'er', 'doi', 'can', 'b', 'c', 'd', 'e',\n",
    "                            'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'o', 'q', 'r', 's',\n",
    "                            't', 'u', 'v', 'w', 'y', 'z']\n",
    "    tokens = text.split()\n",
    "    tokens_without_sw = [word for word in tokens if not word in irrelevant_tokens]\n",
    "    text = ' '.join(tokens_without_sw)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4f1646-a516-4104-80d7-4e91de534854",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in data:\n",
    "    data[key] = preprocess(data[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7647a06-b78c-45a5-91a0-5afceb3b327f",
   "metadata": {
    "id": "b7647a06-b78c-45a5-91a0-5afceb3b327f"
   },
   "outputs": [],
   "source": [
    "# Do NER tagging on a given document\n",
    "def flair_ner(document, model, docid):\n",
    "    results = []\n",
    "    splitter = SegtokSentenceSplitter()\n",
    "    sentences = splitter.split(document)\n",
    "    model.predict(sentences)\n",
    "    for sentence in sentences:        \n",
    "        for entity in sentence.get_spans('ner'):\n",
    "            if (entity.get_label(\"ner\").value in relevant_ent_types):\n",
    "                if (len(entity.text) > 1): # one character entities disregarded\n",
    "                    results.append((entity.text.replace('\"', ''), entity.get_label(\"ner\").value, sentence, docid))\n",
    "                              \n",
    "    return results\n",
    "\n",
    "# Write tagging results to CSV file\n",
    "def write_results_to_file(results, file):\n",
    "    if os.path.exists(file):\n",
    "        # append\n",
    "        with open(file, 'a+', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            for item in results:\n",
    "                writer.writerow([str(item[0]), str(item[1]), str(item[2]), str(item[3]), 'flair - FLERT and XML embeddings'])\n",
    "    else:\n",
    "        # create file from scratch\n",
    "        with open(file, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['entity', 'entity_type', 'sentence', 'docid', 'model'])\n",
    "            for item in results:\n",
    "                writer.writerow([str(item[0]), str(item[1]), str(item[2]), str(item[3]), 'flair - FLERT and XML embeddings'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dfd99a-1cb8-4adb-80b3-847fd5385b4e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7dfd99a-1cb8-4adb-80b3-847fd5385b4e",
    "outputId": "4a573403-ebbd-4f3e-936d-76f4229b3f4b"
   },
   "outputs": [],
   "source": [
    "# Run the NER tagging on each document in the corpus\n",
    "import datetime;\n",
    "ct = datetime.datetime.now()\n",
    "print()\n",
    "print(\"Started entire run at:-\", ct)\n",
    "print(\"---\")\n",
    "print()\n",
    "\n",
    "index = 1\n",
    "for key in data:\n",
    "    ct = datetime.datetime.now()\n",
    "    print(\"Started processing Doc (\" + str(index) + \" / \" + \"55) at:-\", ct)\n",
    "    ner_results = flair_ner(data[key], flair_18class, key)\n",
    "    write_results_to_file(ner_results, 'master-ner-results.csv')\n",
    "    ct = datetime.datetime.now()\n",
    "    print(\"Finished processing Doc (\" + str(index) + \" / \" + \"55) at:-\", ct)\n",
    "    index += 1\n",
    "\n",
    "print()\n",
    "ct = datetime.datetime.now()\n",
    "print(\"---\")\n",
    "print(\"Finished entire run at:-\", ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b8a3a1-f53e-4659-9fe9-0a03a379f588",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ner-flair.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
