{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac965704-7ccc-46cf-9683-99b113a8e9ae",
   "metadata": {},
   "source": [
    "## Word2Vec embeddings\n",
    "\n",
    "This notebook calculates Word2Vec embeddings for each token or phrase in the OECD corpus. We try a variety of models with different vector sizes and context sizes for words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9693a57c-6adb-494d-b425-792cf41b9d8a",
   "metadata": {},
   "source": [
    "### 1. Replace curated ngrams with single tokens in docs\n",
    "\n",
    "There is a curated list of phrases spanning more than one word which represent terms that need a single vector associated with them. This list is given in `ngram_replacements.json`. We replace these with single tokens in this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0765bc1-6af8-46c9-8c1d-3ecbc153d667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/kodymoodley/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../util/') # import python preprocessing script\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "from preprocessing import preprocess_word2vec\n",
    "import json\n",
    "\n",
    "path = Path(os.getcwd())\n",
    "models_dir = os.path.join(path.parents[0], \"models\")\n",
    "data_dir = os.path.join(path.parents[0], \"data-files\")\n",
    "\n",
    "with open(os.path.join(data_dir, \"processed_ngram_ner_data.json\")) as f:\n",
    "    corpus = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3975bb6-8033-4f1a-885b-e17fa14db8de",
   "metadata": {},
   "source": [
    "### 2. Preprocess text for word2vec algorithm\n",
    "\n",
    "Prepare the text for training the embeddings. This performs further preprocessing such as removing stopwords, punctuation and performing lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "453d7281-b7ef-4844-9b28-f39db079b789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all docs into one string\n",
    "corpus_as_str = ''\n",
    "for key in corpus:\n",
    "    corpus_as_str += corpus[key] + '. '\n",
    "\n",
    "processed_corpus = preprocess_word2vec(corpus_as_str, custom_stopwords=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5995876-bcbc-4fbc-8669-18144d0c0e68",
   "metadata": {},
   "source": [
    "### 3. Train the embedding models\n",
    "\n",
    "Try different parameters for vector and window sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9fe021-6321-4b4a-94c3-4119bec50386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad2577a9-9fea-4e98-8e49-5b5422528335",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_100_20 = gensim.models.Word2Vec(sentences=processed_corpus, sg=1, vector_size=100, window=20, workers=4, min_count=2, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "097f2a7c-7b34-4b82-94fb-0747eebec8e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_100_30 = gensim.models.Word2Vec(sentences=processed_corpus, sg=1, vector_size=100, window=30, workers=4, min_count=2, epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4894aef-c8fc-462c-bd1f-04f2b5110586",
   "metadata": {},
   "source": [
    "### 4. Save the embedding models\n",
    "\n",
    "Save the models to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d030692-1dba-4346-b3b6-fad26db09818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(delete=False) as tmp:\n",
    "    filepath_100_20 = os.path.join(models_dir, 'gensim-oecd-word2vec-100-20.model')\n",
    "    filepath_100_30 = os.path.join(models_dir, 'gensim-oecd-word2vec-100-30.model')\n",
    "    model_100_20.save(filepath_100_20)\n",
    "    model_100_30.save(filepath_100_30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898e31a4-fc53-4b14-b6cb-3327c6b7f6e6",
   "metadata": {},
   "source": [
    "### 5. Test the models\n",
    "\n",
    "Explore the quality of the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dc30485-49b0-4d5d-9b3c-b980ea1832f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_testmodel = gensim.models.Word2Vec.load(filepath_100_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3692fc78-1a00-4bbc-8cea-639c3db13b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('financing', 0.7480107545852661),\n",
       " ('investment', 0.7048020362854004),\n",
       " ('commercial', 0.7008841633796692),\n",
       " ('concessional', 0.6848236918449402),\n",
       " ('mobilising', 0.6835558414459229),\n",
       " ('mezzanine', 0.6796742081642151),\n",
       " ('mobilise', 0.6683375835418701),\n",
       " ('blended', 0.6679754257202148),\n",
       " ('attract', 0.6674732565879822),\n",
       " ('debt', 0.6533348560333252),\n",
       " ('leverage', 0.6512179374694824),\n",
       " ('non-concessional', 0.646682620048523),\n",
       " ('organi-sations', 0.6398669481277466),\n",
       " ('repayable', 0.6380059719085693),\n",
       " ('loan', 0.6368876099586487),\n",
       " ('blend', 0.6358164548873901),\n",
       " ('risk-management', 0.6299599409103394),\n",
       " ('repayable_finance', 0.6278873682022095),\n",
       " ('financier', 0.6156778931617737),\n",
       " ('investor', 0.6143190264701843)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_testmodel.wv.most_similar(positive=['finance'], topn=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "04991334-6e99-4898-a176-d07ede459263",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_testmodel = gensim.models.Word2Vec.load(filepath_100_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a2f021f-0aea-4330-a82f-35d9d6d06e2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('financing', 0.7811167240142822),\n",
       " ('commercial', 0.740609884262085),\n",
       " ('investment', 0.7234548926353455),\n",
       " ('blended', 0.6920834183692932),\n",
       " ('attract', 0.684935450553894),\n",
       " ('mobilise', 0.6698009967803955),\n",
       " ('investor', 0.6550965309143066),\n",
       " ('mezzanine', 0.6516242027282715),\n",
       " ('concessional', 0.6506146788597107),\n",
       " ('repayable', 0.6481335163116455),\n",
       " ('debt', 0.6457288861274719),\n",
       " ('repayable_finance', 0.6439858078956604),\n",
       " ('leverage', 0.6382477283477783),\n",
       " ('blend', 0.6378662586212158),\n",
       " ('loan', 0.6332045793533325),\n",
       " ('vipa', 0.6283848285675049),\n",
       " ('financier', 0.6255854368209839),\n",
       " ('organi-sations', 0.6253201365470886),\n",
       " ('blended_finance', 0.6248964667320251),\n",
       " ('mobilising', 0.6224984526634216)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_testmodel.wv.most_similar(positive=['finance'], topn=20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
