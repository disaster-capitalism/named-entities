{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92f4c59-1683-44d3-a57c-02f07c61027b",
   "metadata": {},
   "source": [
    "## Clustering named entities - OECD corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a20ee10-47c1-4e5e-b532-93085808d892",
   "metadata": {},
   "source": [
    "### 1. Import and preprocess named entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccc07ce-dac5-4250-8b8f-9c557b222742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gensim\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import plotly.offline as pyo\n",
    "import plotly.graph_objs as go\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "# import master ner dataset\n",
    "df = pd.read_csv('full-flair-ner-list-oecd-with-single-tokens.csv')\n",
    "\n",
    "# partition dataframe according to main entity types\n",
    "orgs_df = df[df['entity_type'] == 'ORG'] \n",
    "locs_df = df[df['entity_type'] == 'LOC'] \n",
    "gpes_df = df[df['entity_type'] == 'GPE'] \n",
    "persons_df = df[df['entity_type'] == 'PERSON'] \n",
    "\n",
    "# filter only the most frequently occurring entities of each type\n",
    "n = 200\n",
    "orgs = orgs_df['entity_as_single_token'].value_counts().index.tolist()[:n]\n",
    "locs = locs_df['entity_as_single_token'].value_counts().index.tolist()[:n]\n",
    "gpes = gpes_df['entity_as_single_token'].value_counts().index.tolist()[:n]\n",
    "persons = persons_df['entity_as_single_token'].value_counts().index.tolist()[:n]\n",
    "all_entities = list(set((orgs + persons + gpes)))\n",
    "# print(orgs)\n",
    "# print()\n",
    "# print(gpes)\n",
    "# print()\n",
    "# print(persons)\n",
    "# print()\n",
    "# print(all_entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d3b357-3db9-4469-952f-db318d5daba4",
   "metadata": {},
   "source": [
    "### 2. Import and prepare trained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ecb0ce-5b52-4b46-aa92-51e775987e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load chosen model: vector size - 200, window size - 20 \n",
    "# filepath_200_20 = '/Users/kodymoodley/Documents/nlesc-projects/disaster-capitalism/embeddings/models/gensim-oecd-word2vec-200-20.model'\n",
    "# d_testmodel = gensim.models.Word2Vec.load(filepath_200_20)\n",
    "# load chosen model: vector size - 100, window size - 20 \n",
    "filepath_100_20 = '/Users/kodymoodley/Documents/nlesc-projects/disaster-capitalism/embeddings/models/gensim-oecd-word2vec-100-20.model'\n",
    "c_testmodel = gensim.models.Word2Vec.load(filepath_100_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d6841-fcbf-471f-bca8-2c857006f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_vectors = []\n",
    "    \n",
    "words_in_model = []\n",
    "for index, word in enumerate(c_testmodel.wv.index_to_key):\n",
    "    words_in_model.append(word)\n",
    "    all_vectors.append(c_testmodel.wv[word])\n",
    "    \n",
    "# print(len(words_in_model))\n",
    "# print(len(all_vectors))\n",
    "print(words_in_model[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37df66a4-8488-42a4-9d33-5523e5c5e0a1",
   "metadata": {},
   "source": [
    "### 3. Use t-SNE to reduce dimensions of vectors to 2D and 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc742f-aa7d-49c7-9aa0-65cde651eafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to compute 3D / 2D coordinates (dimensionality reduction) for word vectors\n",
    "def get_coordinates(model, vector_size, words, dimensions):\n",
    "    if dimensions not in [2, 3]:\n",
    "        print(\"incorrect number of dimensions: possible values are the integers 2 or 3\")\n",
    "        return [], [], []\n",
    "    \n",
    "    colors = []\n",
    "    vectors = []\n",
    "    labels = []\n",
    "    for wrd in words:\n",
    "        try:\n",
    "            if (wrd in orgs):\n",
    "                curr_color = f'rgb({67}, {198}, {252})'\n",
    "                colors.append(curr_color)\n",
    "            elif (wrd in gpes):\n",
    "                curr_color = f'rgb({253}, {151}, {32})'\n",
    "                colors.append(curr_color)\n",
    "            elif (wrd in persons):\n",
    "                curr_color = f'rgb({166}, {226}, {45})'\n",
    "                colors.append(curr_color)\n",
    "            else:\n",
    "                curr_color = f'rgb({255}, {255}, {255})'\n",
    "                colors.append(curr_color)\n",
    "                \n",
    "            wrd_vector = model.wv[wrd]\n",
    "            vectors.append(wrd_vector)\n",
    "            # arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "            if wrd in (orgs + gpes + persons):\n",
    "                labels.append(wrd)\n",
    "            else:\n",
    "                labels.append('')\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    tsne = TSNE(n_components=dimensions, random_state=0)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = tsne.fit_transform(vectors)\n",
    "    if (dimensions == 2):\n",
    "        x_coords = Y[:, 0]\n",
    "        y_coords = Y[:, 1]\n",
    "        return x_coords, y_coords, colors, labels\n",
    "    else:\n",
    "        x_coords = Y[:, 0]\n",
    "        y_coords = Y[:, 1]\n",
    "        z_coords = Y[:, 2]\n",
    "        return x_coords, y_coords, z_coords, colors, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e653e47-7934-4023-bfc3-e7159a3de04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE clustering\n",
    "x, y, z, colors, labels = get_coordinates(c_testmodel, 100, words_in_model, 3)\n",
    "x, y, colors, labels = get_coordinates(c_testmodel, 100, words_in_model, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9777675-a04a-4cf2-826f-b55a1740e1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_colors_and_labels(old_colors, old_labels, words_in_model, enttypes='org'):\n",
    "    global orgs\n",
    "    global persons\n",
    "    global gpes\n",
    "\n",
    "    new_colors = []\n",
    "    new_labels = []\n",
    "    \n",
    "    selected_type = orgs\n",
    "    \n",
    "    if enttypes == 'org':\n",
    "        selected_type = orgs\n",
    "    elif enttypes == 'per':\n",
    "        selected_type = persons\n",
    "    else:\n",
    "        selected_type = gpes\n",
    "    \n",
    "    for i in range(0, len(words_in_model)):\n",
    "        try:\n",
    "            if words_in_model[i] not in selected_type:\n",
    "                curr_color = f'rgb({255}, {255}, {255})'\n",
    "                new_colors.append(curr_color)\n",
    "                new_labels.append('')\n",
    "            else:\n",
    "                if (words_in_model[i] in orgs):\n",
    "                    curr_color = f'rgb({67}, {198}, {252})'\n",
    "                    new_colors.append(curr_color)\n",
    "                    new_labels.append(words_in_model[i])\n",
    "                elif (words_in_model[i] in gpes):\n",
    "                    curr_color = f'rgb({253}, {151}, {32})'\n",
    "                    new_colors.append(curr_color)\n",
    "                    new_labels.append(words_in_model[i])\n",
    "                elif (words_in_model[i] in persons):\n",
    "                    curr_color = f'rgb({166}, {226}, {45})'\n",
    "                    new_colors.append(curr_color)\n",
    "                    new_labels.append(words_in_model[i])\n",
    "                else:\n",
    "                    curr_color = f'rgb({255}, {255}, {255})'\n",
    "                    new_colors.append(curr_color)   \n",
    "                    new_labels.append('')\n",
    "        except:\n",
    "            pass\n",
    "                    \n",
    "    return new_colors, new_labels\n",
    "\n",
    "org_colors, org_labels = get_colors_and_labels(colors, labels, words_in_model, enttypes='org')\n",
    "per_colors, per_labels = get_colors_and_labels(colors, labels, words_in_model, enttypes='per')\n",
    "gpe_colors, gpe_labels = get_colors_and_labels(colors, labels, words_in_model, enttypes='gpe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cdc9f8-cff6-4741-9c71-e136108d7df1",
   "metadata": {},
   "source": [
    "### 4. Plot the 2D and 3D vectors from t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3461cfe3-ecd0-4514-a07f-cfb177ed9dcd",
   "metadata": {},
   "source": [
    "#### a. All entity types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368e6f2e-b409-4c08-8ca7-a482a2c8fe37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_3d = [go.Scatter3d(x = x,\n",
    "                    y = y,\n",
    "                    z = z,\n",
    "                    mode = 'markers+text',\n",
    "                    text = labels,\n",
    "                    textposition='bottom center',\n",
    "                    hoverinfo = 'text',\n",
    "                    marker=dict(color=colors,size=6,opacity=0.8))]\n",
    "\n",
    "# data = [trace]\n",
    "layout_all_3d = go.Layout(title='OECD actor clusters - ALL TYPES - 3D', autosize=False, width=1000, height=1000)\n",
    "fig_all_3d = go.Figure(data=plot_all_3d, layout=layout_all_3d)\n",
    "pyo.iplot(fig_all_3d) \n",
    "fig_all_3d.write_html(\"cluster-plots/actors-3d-alltypes.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b8e9b4-9d4f-403d-8bb6-96967d98010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_2d = [go.Scatter(x = x,\n",
    "                    y = y,\n",
    "                    mode = 'markers+text',\n",
    "                    text = labels,\n",
    "                    textposition='bottom center',\n",
    "                    hoverinfo = 'text',\n",
    "                    marker=dict(color=colors,size=6,opacity=0.8))]\n",
    "\n",
    "layout_all_2d = go.Layout(title='OECD actor clusters - ALL TYPES - 2D',autosize=False, width=1000, height=1000)\n",
    "fig_all_2d = go.Figure(data=plot_all_2d, layout=layout_all_2d)\n",
    "pyo.iplot(fig_all_2d) \n",
    "fig_all_2d.write_html(\"cluster-plots/actors-2d-alltypes.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f9ba5b-ec40-4ab7-b1fe-1d8e6284b122",
   "metadata": {},
   "source": [
    "#### b. ORGs only\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b6ace-7a86-4ef1-9df3-6f3bddd2ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_3d = [go.Scatter3d(x = x,\n",
    "                    y = y,\n",
    "                    z = z,\n",
    "                    mode = 'markers+text',\n",
    "                    text = org_labels,\n",
    "                    textposition='bottom center',\n",
    "                    hoverinfo = 'text',\n",
    "                    marker=dict(color=org_colors,size=6,opacity=0.8))]\n",
    "\n",
    "# data = [trace]\n",
    "layout_all_3d = go.Layout(title='OECD actor clusters - ORGs - 3D', autosize=False, width=1000, height=1000)\n",
    "fig_all_3d = go.Figure(data=plot_all_3d, layout=layout_all_3d)\n",
    "pyo.iplot(fig_all_3d) \n",
    "fig_all_3d.write_html(\"cluster-plots/actors-3d-orgs.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d46f07-7c05-40f4-a90d-a48538244540",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_2d = [go.Scatter(x = x,\n",
    "                    y = y,\n",
    "                    mode = 'markers+text',\n",
    "                    text = org_labels,\n",
    "                    textposition='bottom center',\n",
    "                    hoverinfo = 'text',\n",
    "                    marker=dict(color=org_colors,size=6,opacity=0.8))]\n",
    "\n",
    "layout_all_2d = go.Layout(title='OECD actor clusters - ORGs - 2D',autosize=False, width=1000, height=1000)\n",
    "fig_all_2d = go.Figure(data=plot_all_2d, layout=layout_all_2d)\n",
    "pyo.iplot(fig_all_2d) \n",
    "fig_all_2d.write_html(\"cluster-plots/actors-2d-orgs.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a94380f-0796-4f91-a9d6-0b6361e1f1a2",
   "metadata": {},
   "source": [
    "#### c. PERs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf90bcc-5e04-4f2d-8abe-4b7a40ec8144",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_3d = [go.Scatter3d(x = x,\n",
    "                    y = y,\n",
    "                    z = z,\n",
    "                    mode = 'markers+text',\n",
    "                    text = per_labels,\n",
    "                    textposition='bottom center',\n",
    "                    hoverinfo = 'text',\n",
    "                    marker=dict(color=per_colors,size=6,opacity=0.8))]\n",
    "\n",
    "# data = [trace]\n",
    "layout_all_3d = go.Layout(title='OECD actor clusters - PERSONs - 3D', autosize=False, width=1000, height=1000)\n",
    "fig_all_3d = go.Figure(data=plot_all_3d, layout=layout_all_3d)\n",
    "pyo.iplot(fig_all_3d) \n",
    "fig_all_3d.write_html(\"cluster-plots/actors-3d-persons.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad90c5f3-976b-495a-bba1-a1b6859ceeb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_2d = [go.Scatter(x = x,\n",
    "                    y = y,\n",
    "                    mode = 'markers+text',\n",
    "                    text = per_labels,\n",
    "                    textposition='bottom center',\n",
    "                    hoverinfo = 'text',\n",
    "                    marker=dict(color=per_colors,size=6,opacity=0.8))]\n",
    "\n",
    "layout_all_2d = go.Layout(title='OECD actor clusters - PERSONs - 2D',autosize=False, width=1000, height=1000)\n",
    "fig_all_2d = go.Figure(data=plot_all_2d, layout=layout_all_2d)\n",
    "pyo.iplot(fig_all_2d) \n",
    "fig_all_2d.write_html(\"cluster-plots/actors-2d-persons.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c69d790-1f31-4a64-888c-f7665ade5456",
   "metadata": {},
   "source": [
    "#### d. GPEs only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a3ab6d-7e64-453f-a735-aa9ceafbcfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_3d = [go.Scatter3d(x = x,\n",
    "                    y = y,\n",
    "                    z = z,\n",
    "                    mode = 'markers+text',\n",
    "                    text = gpe_labels,\n",
    "                    textposition='bottom center',\n",
    "                    hoverinfo = 'text',\n",
    "                    marker=dict(color=gpe_colors,size=6,opacity=0.8))]\n",
    "\n",
    "# data = [trace]\n",
    "layout_all_3d = go.Layout(title='OECD actor clusters - GPEs - 3D', autosize=False, width=1000, height=1000)\n",
    "fig_all_3d = go.Figure(data=plot_all_3d, layout=layout_all_3d)\n",
    "pyo.iplot(fig_all_3d) \n",
    "fig_all_3d.write_html(\"cluster-plots/actors-3d-gpes.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4609c3-cfdf-451a-9144-ded6b5e8f3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_all_2d = [go.Scatter(x = x,\n",
    "                    y = y,\n",
    "                    mode = 'markers+text',\n",
    "                    text = gpe_labels,\n",
    "                    textposition='bottom center',\n",
    "                    hoverinfo = 'text',\n",
    "                    marker=dict(color=gpe_colors,size=6,opacity=0.8))]\n",
    "\n",
    "layout_all_2d = go.Layout(title='OECD actor clusters - GPEs - 2D',autosize=False, width=1000, height=1000)\n",
    "fig_all_2d = go.Figure(data=plot_all_2d, layout=layout_all_2d)\n",
    "pyo.iplot(fig_all_2d) \n",
    "fig_all_2d.write_html(\"cluster-plots/actors-2d-gpes.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903e31d2-aa9f-449b-a4a1-1335057ae2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_more_info_about_entity(entity):\n",
    "    global df\n",
    "    new_df = df.drop(['entity', 'model'], axis=1)\n",
    "    relevant_df = new_df[new_df['entity_as_single_token'] == entity].reset_index(drop=True)\n",
    "    types = list(set(relevant_df['entity_type'].tolist()))\n",
    "    docs = list(set(relevant_df['docid'].tolist()))\n",
    "    potential_contexts = relevant_df['sentence'].tolist()\n",
    "    new_contexts = []\n",
    "    spans = relevant_df['span'].tolist()\n",
    "    for i in range(0, len(potential_contexts)):\n",
    "        span_parts = spans[i].split(':')\n",
    "        l_span = int(span_parts[0])\n",
    "        r_span = int(span_parts[1])\n",
    "        left_str = potential_contexts[i][:l_span-1]\n",
    "        right_str = potential_contexts[i][r_span+1:]\n",
    "        left_str_parts = left_str.split()\n",
    "        right_str_parts = right_str.split()\n",
    "        if ((len(left_str_parts) > 3) or (len(right_str_parts) > 3)):\n",
    "            if (len(left_str_parts) <= 3):\n",
    "                new_str = potential_contexts[i][:r_span] + ' ' + ' '.join(right_str_parts[0:3])\n",
    "                new_contexts.append(new_str)\n",
    "            elif (len(right_str_parts) <= 3):\n",
    "                new_str = ' '.join(left_str_parts[-3:]) + ' ' + potential_contexts[i][l_span:]\n",
    "                new_contexts.append(new_str)\n",
    "            else:\n",
    "                new_str = ' '.join(left_str_parts[-3:]) + ' ' + potential_contexts[i][l_span:r_span] +  ' ' + ' '.join(right_str_parts[0:3])\n",
    "                new_contexts.append(new_str)\n",
    "        else:\n",
    "            new_contexts.append(potential_contexts[i])\n",
    "    return {'name' : entity, 'types' : types, 'docs' : docs, 'contexts' : new_contexts}\n",
    "\n",
    "def pretty_print_entity_info(entity_info):\n",
    "    print()\n",
    "    print(\"name\\t\\t:\\t\", entity_info['name']) \n",
    "    print()\n",
    "    print(\"types\\t\\t:\\t\", entity_info['types'])\n",
    "    print()\n",
    "    print(\"documents\\t:\\t\", entity_info['docs'])\n",
    "    print()\n",
    "    print(\"contexts\\t:\\t\", end=\"\")\n",
    "    print(\" 1. \" + entity_info['contexts'][0])\n",
    "    for i in range(1, len(entity_info['contexts'])):\n",
    "        print(\"\\t\\t\\t \" + str(i+1) + \". \" + entity_info['contexts'][i])\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8d08af-fe88-4a36-8492-1f61a075dc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_more_info_about_entity('ibnet')\n",
    "print(pretty_print_entity_info(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4da5af-678b-4acb-b189-d4d1064176c9",
   "metadata": {},
   "source": [
    "### 5. KMeans clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5dc567-0ee8-4039-98c4-3be138700f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.cluster import KMeansClusterer\n",
    "import nltk\n",
    "NUM_CLUSTERS=30\n",
    "X = all_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27bbc48c-b0cb-4265-94aa-d669d192a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kclusterer = KMeansClusterer(NUM_CLUSTERS, distance=nltk.cluster.util.cosine_distance, repeats=25)\n",
    "assigned_clusters = kclusterer.cluster(X, assign_clusters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cc0336-35f6-4bbb-82f5-40d03eacab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_word_from_word2vec(vector, model):\n",
    "    for index, word in enumerate(model.wv.index_to_key):\n",
    "        if model.wv[word].tolist() == vector.tolist():\n",
    "            return word\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb469d3d-ad40-4b20-bbe3-b57b913b6d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = {}\n",
    "raw_clusters=[]\n",
    "cluster_indexes = set()\n",
    "for index, word in enumerate(c_testmodel.wv.index_to_key):\n",
    "    cluster_indexes.add(assigned_clusters[index])\n",
    "    clusters[assigned_clusters[index]] = []\n",
    "    raw_clusters.append((assigned_clusters[index], word))\n",
    "    \n",
    "for item in raw_clusters:\n",
    "    clusters[item[0]].append(item[1])\n",
    "    \n",
    "import json\n",
    "with open('clustering-data/kmeans_clusters.json', 'w') as fp:\n",
    "    json.dump(clusters, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302daec5-883b-4179-ad57-c46b8b8bf527",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter clusters only for ORGS, PER, GPEs\n",
    "\n",
    "orgs_clusters = {}\n",
    "persons_clusters = {}\n",
    "gpes_clusters = {}\n",
    "for key in clusters:\n",
    "    orgs_clusters[key] = []\n",
    "    persons_clusters[key] = []\n",
    "    gpes_clusters[key] = []\n",
    "    for word in clusters[key]:\n",
    "        if word in orgs:\n",
    "            orgs_clusters[key].append(word)\n",
    "        if word in persons:\n",
    "            persons_clusters[key].append(word)\n",
    "        if word in gpes:\n",
    "            gpes_clusters[key].append(word)\n",
    "          \n",
    "    if len(orgs_clusters[key]) == 0:\n",
    "        del orgs_clusters[key]\n",
    "    if len(persons_clusters[key]) == 0:\n",
    "        del persons_clusters[key]\n",
    "    if len(gpes_clusters[key]) == 0:\n",
    "        del gpes_clusters[key]\n",
    "    \n",
    "with open('clustering-data/kmeans_clusters_orgs.json', 'w') as fp:\n",
    "    json.dump(orgs_clusters, fp)\n",
    "\n",
    "with open('clustering-data/kmeans_clusters_persons.json', 'w') as fp:\n",
    "    json.dump(persons_clusters, fp)\n",
    "    \n",
    "with open('clustering-data/kmeans_clusters_gpes.json', 'w') as fp:\n",
    "    json.dump(gpes_clusters, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6676bca4-3a10-41aa-8cf7-2f2504232e34",
   "metadata": {},
   "source": [
    "### 6. Spectral clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0ff113-fc75-4934-a500-720743d5fdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "import numpy as np\n",
    "sp_clustering = SpectralClustering(n_clusters=30, assign_labels='discretizeâ€™',random_state=0).fit(X)\n",
    "print(sp_clustering.labels_)\n",
    "print(sp_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f687c31-ec03-411d-b05f-46a20c2c8fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sp_clustering.labels_)\n",
    "# len(list(set(sp_clustering.labels_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccbf788-dd5b-4cb5-a2dd-8efce701e5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp_clusters = {}\n",
    "raw_sp_clusters=[]\n",
    "cluster_sp_indexes = set()\n",
    "for index, word in enumerate(c_testmodel.wv.index_to_key):\n",
    "    cluster_sp_indexes.add(int(sp_clustering.labels_[index]))\n",
    "    sp_clusters[int(sp_clustering.labels_[index])] = []\n",
    "    raw_sp_clusters.append((int(sp_clustering.labels_[index]), word))\n",
    "    \n",
    "for item in raw_sp_clusters:\n",
    "    sp_clusters[item[0]].append(item[1])\n",
    "    \n",
    "with open('clustering-data/spectral_clusters.json', 'w') as fp:\n",
    "    json.dump(sp_clusters, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3da525-50f8-4381-9b91-e3ce738f79fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter clusters only for ORGS, PER, GPEs\n",
    "\n",
    "orgs_sp_clusters = {}\n",
    "persons_sp_clusters = {}\n",
    "gpes_sp_clusters = {}\n",
    "for key in sp_clusters:\n",
    "    orgs_sp_clusters[key] = []\n",
    "    persons_sp_clusters[key] = []\n",
    "    gpes_sp_clusters[key] = []\n",
    "    for word in sp_clusters[key]:\n",
    "        if word in orgs:\n",
    "            orgs_sp_clusters[key].append(word)\n",
    "        if word in persons:\n",
    "            persons_sp_clusters[key].append(word)\n",
    "        if word in gpes:\n",
    "            gpes_sp_clusters[key].append(word)\n",
    "          \n",
    "    if len(orgs_sp_clusters[key]) == 0:\n",
    "        del orgs_sp_clusters[key]\n",
    "    if len(persons_sp_clusters[key]) == 0:\n",
    "        del persons_sp_clusters[key]\n",
    "    if len(gpes_sp_clusters[key]) == 0:\n",
    "        del gpes_sp_clusters[key]\n",
    "    \n",
    "with open('clustering-data/spectral_clusters_orgs.json', 'w') as fp:\n",
    "    json.dump(orgs_sp_clusters, fp)\n",
    "\n",
    "with open('clustering-data/spectral_clusters_persons.json', 'w') as fp:\n",
    "    json.dump(persons_sp_clusters, fp)\n",
    "    \n",
    "with open('clustering-data/spectral_clusters_gpes.json', 'w') as fp:\n",
    "    json.dump(gpes_sp_clusters, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b2a63b-b9b8-4048-a43a-24dc8f1a1cc3",
   "metadata": {},
   "source": [
    "### 7. Find closest actors to each STM topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99cb6a7-9f20-472a-bad8-c03f660ba96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import topics from STM and link them (using fuzzy string matching) to the word form present in the word embeddings list\n",
    "# This is necessary because stemming is used in the STM topic words while it is not used for generating the word embeddings\n",
    "# because lemmatization generally improves the quality of embeddings over stemming because it takes into account the meaning\n",
    "# of the word in reducing it to a canonical form. stemming does not.\n",
    "\n",
    "from thefuzz import fuzz\n",
    "from thefuzz import process\n",
    "\n",
    "def find_partial_match(given_word):\n",
    "    global words_in_model       \n",
    "    \n",
    "    match = process.extractOne(given_word, words_in_model, scorer=fuzz.token_set_ratio, score_cutoff=80)\n",
    "    \n",
    "    if (match is not None):\n",
    "        if (match[1] >= 90):\n",
    "            return match[0]\n",
    "        else:\n",
    "            for word in words_in_model:\n",
    "                if given_word.strip() == word[:len(given_word)].strip():\n",
    "                    return word\n",
    "            for word in words_in_model:\n",
    "                if given_word.strip()[:len(given_word.strip())-1] == word[:len(given_word.strip())-1].strip():\n",
    "                    return word\n",
    "    else:\n",
    "        for word in words_in_model:\n",
    "            if given_word.strip() == word[:len(given_word)].strip():\n",
    "                return word\n",
    "        for word in words_in_model:\n",
    "                if given_word.strip()[:len(given_word.strip())-1] == word[:len(given_word.strip())-1].strip():\n",
    "                    return word\n",
    "\n",
    "    return None\n",
    "\n",
    "def get_word2vec_topic_words(topics):\n",
    "    global words_in_model\n",
    "        \n",
    "    word2vec_topics = []\n",
    "    \n",
    "    for word in topics:\n",
    "        if (word in words_in_model): # already verbatim in there\n",
    "            word2vec_topics.append(word)\n",
    "        else:\n",
    "            word = word.replace('-', '_')\n",
    "            match = process.extractOne(word, words_in_model, scorer=fuzz.token_set_ratio, score_cutoff = 91)\n",
    "            if match is not None:\n",
    "                # print(word, \"\\t:\\t\", match)\n",
    "                word2vec_topics.append(match[0])\n",
    "            else:\n",
    "                partial_match = find_partial_match(word)\n",
    "                if partial_match is not None:\n",
    "                    # print(word, \"\\t:\\t\", partial_match)\n",
    "                    word2vec_topics.append(partial_match)\n",
    "                # else:\n",
    "                #     print(word, \"\\t:\\t\", partial_match)\n",
    "\n",
    "    return list(set(word2vec_topics))\n",
    "    \n",
    "def map_topics_words_to_word2vec_vocab(stm_topics_df):\n",
    "    results = {}\n",
    "    unique_topic_ids = stm_topics_df.id.unique()\n",
    "    \n",
    "    for topic_id in unique_topic_ids:\n",
    "        print(topic_id, ' : ', len(unique_topic_ids))\n",
    "        topic_id_df = stm_topics_df[stm_topics_df['id'] == topic_id]\n",
    "        topic_id_df = topic_id_df.drop(['id', 'metric'], axis=1)\n",
    "        df_values = topic_id_df.values.tolist()\n",
    "\n",
    "        topic_words_as_list = [item.strip() for sublist in df_values for item in sublist]\n",
    "\n",
    "        word2vec_topics = get_word2vec_topic_words(topic_words_as_list)\n",
    "        results[int(topic_id)] = word2vec_topics\n",
    "        \n",
    "    return results\n",
    "    \n",
    "stm_topics_df = pd.read_csv('stm_final_topic_labels.csv', sep=';')\n",
    "\n",
    "results_dict = map_topics_words_to_word2vec_vocab(stm_topics_df)\n",
    "\n",
    "with open('clustering-data/stm_topics_word2vec_vocab.json', 'w') as fp:\n",
    "    json.dump(results_dict, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc6a0b-9245-4298-bc32-6bbedca9f25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kmeans clusters for actors (ORGs)\n",
    "\n",
    "similarity_results = {}\n",
    "\n",
    "for topic_key in results_dict: # for each topic\n",
    "    similarity_results[topic_key] = {}\n",
    "    for org_cluster_key in orgs_clusters: # for each cluster\n",
    "        sim = c_testmodel.wv.n_similarity(results_dict[topic_key], orgs_clusters[org_cluster_key])\n",
    "        similarity_results[topic_key][org_cluster_key] = str(sim)\n",
    "\n",
    "for item in similarity_results:\n",
    "    highest = 0.0\n",
    "    highest_subitem = 0\n",
    "    for subitem in similarity_results[item]:\n",
    "        if float(similarity_results[item][subitem]) > float(highest):\n",
    "            highest = similarity_results[item][subitem]\n",
    "            highest_subitem = subitem\n",
    "            \n",
    "    similarity_results[item]['highest'] = highest_subitem\n",
    "    \n",
    "with open('clustering-data/stm_topics_vs_org_clusters_kmeans.json', 'w') as fp:\n",
    "    json.dump(similarity_results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107c38a-5fe0-4e33-a536-ece5a1657849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectral clusters for actors (ORGs)\n",
    "\n",
    "similarity_results_sp = {}\n",
    "\n",
    "for topic_key in results_dict: # for each topic\n",
    "    similarity_results_sp[topic_key] = {}\n",
    "    for org_cluster_key in orgs_sp_clusters: # for each cluster\n",
    "        sim = c_testmodel.wv.n_similarity(results_dict[topic_key], orgs_sp_clusters[org_cluster_key])\n",
    "        similarity_results_sp[topic_key][org_cluster_key] = str(sim)\n",
    "\n",
    "for item in similarity_results_sp:\n",
    "    highest = 0\n",
    "    highest_subitem = 0\n",
    "    for subitem in similarity_results_sp[item]:\n",
    "        if float(similarity_results_sp[item][subitem]) > float(highest):\n",
    "            highest = subitem\n",
    "            highest_subitem = subitem\n",
    "            \n",
    "    similarity_results_sp[item]['highest'] = highest_subitem\n",
    "    \n",
    "with open('clustering-data/stm_topics_vs_org_clusters_spectral.json', 'w') as fp:\n",
    "    json.dump(similarity_results_sp, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac2a015-ad66-4e34-9ccd-7e8edba76f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"STM topics mapping to Kmeans clusters (ORGs):\")\n",
    "print(\"---------------------------------------------\")\n",
    "print()\n",
    "for item in similarity_results:\n",
    "    print(item, \" : \", similarity_results[item]['highest'])\n",
    "print()\n",
    "print()\n",
    "print(\"STM topics mapping to Spectral clusters (ORGs):\")\n",
    "print(\"-----------------------------------------------\")\n",
    "print()\n",
    "for item in similarity_results_sp:\n",
    "    print(item, \" : \", similarity_results_sp[item]['highest'])\n",
    "print()\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
